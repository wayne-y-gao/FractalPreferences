\documentclass[12pt,letterpaper]{article}

% ---- Packages ----
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amsthm,mathtools}
\usepackage{geometry}
\geometry{margin=1in}
\usepackage[dvipsnames]{xcolor}
\usepackage{hyperref}
\hypersetup{colorlinks=true,linkcolor=MidnightBlue,citecolor=MidnightBlue,urlcolor=MidnightBlue}
\usepackage{enumitem}
\usepackage{natbib}
\bibliographystyle{plainnat}
\usepackage{booktabs}
\usepackage{array}
\usepackage{setspace}
\onehalfspacing
\usepackage{titlesec}
\usepackage{cleveref}

% ---- Theorem environments ----
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}
\newtheorem{conjecture}[theorem]{Conjecture}

% ---- Custom commands ----
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Haus}{\mathcal{H}}
\newcommand{\dimH}{\dim_{\mathrm{H}}}
\newcommand{\dimB}{\dim_{\mathrm{B}}}
\newcommand{\dH}{D_H}
\newcommand{\dB}{D_B}
\newcommand{\BV}{\mathrm{BV}}
\newcommand{\TV}{\mathrm{TV}}
\newcommand{\dd}{\,\mathrm{d}}
\DeclareMathOperator{\tr}{tr}

% ---- Title ----
\title{\textbf{The Fractal Nature and the Hausdorff Dimension of Individual Heterogeneity}\\
	\Large \emph{A Vibe Research Project\footnote{This draft was produced collaboratively with generative AI tools (Claude, Gemini, ChatGPT, and Refine). See \hyperref[sec:workflow]{Description of Vibe Research Workflow} on the next page.}}}

\author{Prompted and Managed by Wayne Gao\thanks{Department of Economics, University of Pennsylvania. Email: \texttt{waynegao@upenn.edu}.}\\ AI Tools: Claude, Gemini, ChatGPT and Refine}
\date{\today}

\begin{document}
	\maketitle
	
	\begin{abstract}
		\noindent Generative AI is collapsing the cost of general-purpose knowledge toward zero, shifting economic value to the \emph{local instance}---the unique collision of individual preference, temporal context, and spatial circumstance. Standard economics and econometrics has long relegated individual heterogeneity to the ``error'' term, often to be averaged over or discarded away. AI changes this calculus: what was once noise may be a goldmine. But how complex is individual heterogeneity, and what are the returns to resolving it at ever-finer scales? We propose that preference heterogeneity possesses fractal structure with Hausdorff dimension $\dH > 1$: like a coastline, it reveals new detail at every resolution, and no finite level of personalization fully exhausts its economic content. Motivation comes from discrete choice theory, where the natural alternative to pathological iid taste shocks (Berry and Pakes 2007; Lu and Saito 2025)---Brownian heterogeneity---has graph dimension $3/2$ and infinite total variation, and from high-frequency finance, where the same property creates a ``coastline paradox'' for measured volatility. We formalize this via utility on fractal preference manifolds, a Coastline Paradox for Surplus, a Respiration Equilibrium sustaining public knowledge through private optimization, and IFS-based identification of recursive preference rules.
		
		\medskip
		\noindent \textbf{Keywords:} Hausdorff dimension, fractal preferences, geometric measure theory, Brownian motion, pure characteristic models, personalization surplus
	\end{abstract}
	
	\newpage
	
	%% ==========================================================================
	\section*{Description of Vibe Research Workflow}
	\label{sec:workflow}
	\addcontentsline{toc}{section}{Description of Vibe Research Workflow}
	%% ==========================================================================
	
	This is a \emph{vibe research} project. The project started with a back-and-forth voice chat between me and Gemini Live as a continuation of the essay ``Towards a Distributed Knowledge Atmosphere'' (Gao 2026), while I was going through PhD admission files, drafting undergraduate midterm exam questions, and revising a working paper on submanifold integrals with respect to the Hausdorff measure. A Gemini-generated summary of our conversation was then sent to Gemini, Claude, and ChatGPT in their respective Deep Research/Think mode for initial drafts, which were then integrated together by Claude. The draft was then reviewed by Refine.ink, Claude, Gemini, and ChatGPT, whose comments were addressed, incorporated, or dismissed by Claude. I then edited multiple parts of the drafts by hand and by prompts, with an emphasis on the ideas rather than the details.
	
	While the draft's starting point and main directions of inquiries reflect my intentions, I have not fully reviewed the content in its entirety and cannot attest to its full correctness (partly because some of the concepts and results require background knowledge beyond my current area of expertise). To summarize, this is a good-faith effort whose primary goal is to be thought-provoking---to sketch connections, pose questions, and invite intellectual adventure---rather than to meet the standard of fully rigorous academic research. Readers should treat it more as a science-fiction novel than an academic working paper, at least in its current form.
	
	%\newpage
	~
	
	%% ==========================================================================
	\section{Introduction}
	\label{sec:intro}
	%% ==========================================================================
	
	The rapid rise of generative AI---large language models, music generators (Suno), video synthesizers (Seedance), code assistants---has collapsed the marginal cost of producing ``general intelligence'' outputs to near zero. High-level logical reasoning, text generation, and broad-pattern synthesis are becoming social utilities, analogous to electricity. This phenomenon, which we term the \emph{Economic Suicide of Generality}, transforms the locus of economic value. When general answers are free, value migrates to the \emph{Local Instance}: the unique, high-entropy collision of individual preference, temporal context, and spatial circumstance.
	
	\subsection*{The Instance Economy}
	
	What makes the Local Instance economically potent is that AI does not merely shift demand toward personalization---it simultaneously makes personalization \emph{feasible} at previously impossible resolutions. When an AI assistant helps a researcher debug a proof at 2~a.m., translates a pediatrician's instructions into a grandparent's dialect, or adapts a generic supply-chain blueprint to the metallurgy of a specific supplier, it is solving a problem that only one person needs solved, right now. The solution is produced not for resale but for immediate private use. Yet the act of solving generates a byproduct---training signal, gradient updates, usage patterns---that recycles into the broader knowledge system. The individual extracts context-specific utility; the system gets smarter. This \emph{Reciprocal Metabolism} (Gao 2026) ensures that the intellectual commons stays fresh without requiring artificial scarcities, and it means that the supply-side cost of personalization is plummeting at the same time as the demand-side value is rising.
	
	The binding constraint in this regime is no longer algorithmic capacity but the \emph{human utility function} itself. Supply-side costs can be driven to zero by technology; demand-side preferences cannot, because they are not produced---they are \emph{possessed}. They reside inside individual human nodes and nowhere else. If an AI can generate ten thousand adequate melodies, the value lies not in the generation but in the \emph{selection}. The scarce act is not production but judgment---the revealed expression of a utility function encountering a specific choice set at a specific moment. In the old regime, economic power accrued to whoever controlled the means of production; in the emerging regime, it shifts to whoever provides the \emph{intent}.
	
	Here lies a provocative analogy. The individual is the atom of economics---the irreducible unit from which all market phenomena emerge. Just as nuclear physics revealed that the atom, far from being a featureless point, contains vast energy locked in its internal structure ($E = mc^2$), we argue that the individual, far from being a representative agent with a smooth utility function, contains a fractal interior of preference structure whose economic energy is largely unexploited. Technological progress typically enables people to travel further into external worlds---to reach new markets, new products, new information. But sometimes the real treasure is buried within the nucleus of the self: the infinite-resolution structure of what a person actually wants, moment by moment, context by context. AI-driven personalization is the technology that finally cracks this nucleus open.
	
	The intuition that ``there is always more detail inside'' connects to two established research literatures that have independently grappled with the consequences of fine-grained heterogeneity: high-frequency finance and discrete choice modeling. In high-frequency finance, the infinite total variation of price paths (a consequence of their semimartingale structure) means that measured volatility increases with sampling frequency---a ``coastline paradox'' for financial markets. In discrete choice theory, the dominant mixed logit framework's reliance on iid taste shocks generates pathological behavior precisely where personalization matters most. We discuss the latter in detail next.
	
	\subsection*{The iid Taste-Shock Problem}
	
	The standard approach to individual heterogeneity in discrete choice---from McFadden (1974) through BLP (Berry, Levinsohn, and Pakes 1995) and its descendants---models unobserved preference differences by adding iid taste shocks $\epsilon_{ij}$ to each product $j$ for each consumer $i$:
	\[
	U_{ij} = f(X_j, z_i; \theta) + \sum_k v_{ik} X_{jk} + \epsilon_{ij}.
	\]
	The iid shocks, typically extreme-value distributed, yield the mixed logit family and deliver powerful computational advantages: closed-form choice probabilities, smooth likelihoods, and an invertible share equation. But they also impose structural pathologies that become severe precisely in the regime where personalization matters most.
	
	Berry and Pakes (2007) identified two such pathologies in the ``tastes for products'' framework. First, markups remain bounded away from zero even as the product space fills up with near-identical options, because the iid shocks always deliver some consumers to each product regardless of how similar it is to its neighbors. Second, every consumer's utility grows without bound as the number of products increases, regardless of product characteristics---an implication that is economically incoherent and distorts welfare calculations for new goods. Neither pathology arises in their \emph{pure characteristic model}, where $\epsilon_{ij} = 0$ and all heterogeneity flows through continuous interactions $\sum_k v_{ik} X_{jk}$.
	
	Lu and Saito (2025) sharpened this distinction with two formal impossibility results. They proved that all mixed logit models violate \emph{continuity in characteristics}: as two products' characteristics converge, mixed logit still assigns each a nontrivial individual market share, because the iid shocks dominate at close range. They also showed that all non-degenerate mixed logit models violate \emph{convex substitutability}: introducing an intermediate product fails to draw demand from extreme products in the way that spatial intuition (and the Hotelling model) would predict. Both properties hold generically in pure characteristic models. The two model classes have \emph{empty intersection}---they are genuinely distinct, and mixed logit's approximation of pure characteristics fails uniformly even across menus of three products.
	
	\subsection*{Brownian Motion as the Natural Alternative}
	
	If iid taste shocks are the wrong model of heterogeneity, what replaces them? The pure characteristic framework requires that unobserved utility be \emph{continuous in product characteristics}. The simplest stochastic specification satisfying this requirement is Brownian motion: Lu and Saito's Example~5 explicitly constructs a pure characteristic model with $u(x) = v(x) + \varepsilon(x)$, where $\varepsilon(\cdot)$ follows a Brownian motion on the characteristic space. Products with similar characteristics then exhibit similar utility realizations, eliminating the pathological discontinuities of mixed logit.
	
	But Brownian motion has a fundamental geometric property: its sample paths have \emph{infinite total variation} and graph dimension $3/2 > 1$ (Taylor 1953). This means that the preference function $u(\cdot)$, viewed as a curve in characteristic-utility space, is a fractal object---continuous but nowhere differentiable, with detail at every scale. Standard econometrics, treating heterogeneity as draws from a smooth (Lebesgue-continuous, finite-variation) distribution, is structurally mismatched to this geometry. The linear model $y_i = x_i'\beta + \varepsilon_i$ relegates all individual-specific deviation to $\varepsilon_i$ and assumes it is either iid noise (the mixed logit pathology) or smooth variation (which misses the infinite-variation structure). We posit that this ``roughness'' is not noise but \emph{structure}---specifically, fractal structure whose correct mathematical description requires geometric measure theory and Hausdorff dimension.
	
	\subsection*{The Fractal Economy Hypothesis}
	
	Our central hypothesis invokes the \emph{Coastline Paradox} (Mandelbrot 1967) as a formal analogy. Just as the measured length of Britain's coastline diverges as the measurement ruler shrinks ($L(\delta) \propto \delta^{1-D}$ with $D > 1$), the geometric complexity of individual preferences grows without saturation as the resolution of personalization improves. We formalize this in two complementary ways: a static fractal-geometry argument showing that total variation of preferences diverges when box-counting dimension $\dB > 1$, and a continuous-time stochastic formulation in which individual ideal points follow Brownian motion and the tracking loss from coarse personalization scales linearly in the mesh size $\Delta$. The Brownian formulation---where paths have infinite total variation but finite quadratic variation---connects directly to the high-frequency finance literature, where infinite path variation was historically a ``bug'' (transaction costs proportional to trading frequency). We reinterpret this as a ``feature'': there is preference structure at \emph{every} scale, and any finite-resolution technology leaves systematic surplus unexploited.
	
	The transition from mixed logit to pure characteristics is therefore not merely a modeling refinement---it is a change of geometric regime. Under mixed logit, heterogeneity lives in a product-indexed iid noise vector whose dimension grows with the number of products; its structure is featureless by construction. Under pure characteristics with Brownian-type heterogeneity, preferences live on a fractal manifold of fixed Hausdorff dimension $\dH > 1$, carrying rich geometric structure that can be measured, estimated, and exploited.
	
	\subsection*{Overview}
	
	This paper formalizes the fractal economy hypothesis across four pillars:
	\begin{enumerate}[label=(\roman*)]
		\item \textbf{The Hausdorff Utility Function} (\Cref{sec:pillar1}): utility defined on fractal preference manifolds, with economic value interpreted as Hausdorff measure.
		\item \textbf{Divergence of Bespoke Surplus} (\Cref{sec:pillar2}): a formal proof that the geometric complexity of personalization grows without bound when preferences have $\dB > 1$, with economic divergence governed by a joint scaling condition on variation and monetizability.
		\item \textbf{The Reciprocal Knowledge Metabolism} (\Cref{sec:pillar3}): a game-theoretic model of decentralized knowledge production via federated learning.
		\item \textbf{Fractal Identification} (\Cref{sec:pillar4}): IFS-based econometric identification of recursive preference rules.
	\end{enumerate}
	
	We use geometric measure theory as the primary mathematical lens, draw connections to discrete choice theory---including the pure characteristic models of Berry and Pakes (2007), the moderate utility models of He and Natenzon (2024), and the impossibility results of Lu and Saito (2025)---reconcile our findings with the Fundamental Theorems of Welfare Economics (\Cref{sec:welfare}), and address the Aggregation Problem (\Cref{sec:aggregation}).
	
	%% ==========================================================================
	\section{Pillar 1: Economic Value as Hausdorff Measure}
	\label{sec:pillar1}
	%% ==========================================================================
	
	\subsection{Setup: The Fractal Preference Space}
	
	Let $\Theta \subset \R^k$ denote the space of consumer types. In standard theory, $\Theta$ is endowed with Lebesgue measure $\lambda^k$ and types are drawn from a density $f(\theta)$ with respect to $\lambda^k$. We relax this assumption.
	
	\begin{definition}[Fractal Preference Space]
		A \emph{fractal preference space} is a compact set $P \subset \R^k$ with
		\[
		\dimH(P) = \dH \in (d, k), \quad d = \dim_{\mathrm{top}}(P),
		\]
		where $\dimH$ denotes Hausdorff dimension and $\dim_{\mathrm{top}}$ denotes topological dimension. Consumer types $\theta$ are supported on $P$.
	\end{definition}
	
	Three interpretations of the fractal domain are possible, each generating distinct economic content:
	
	\begin{enumerate}[label=(\alph*)]
		\item \textbf{$P$ as type space.} Consumer types $\theta \in P \subset \R^k$ concentrate on a fractal subset. Utility $U: P \times X \to \R$ maps type--bundle pairs to values. Aggregate welfare is
		\begin{equation}\label{eq:hausdorff-welfare}
			V(P) = \int_P U(\theta, x^*(\theta))\, d\Haus^{\dH}(\theta),
		\end{equation}
		where $\Haus^{\dH}$ is the $\dH$-dimensional Hausdorff measure and $x^*(\theta)$ is the optimal bundle for type $\theta$. More precisely, aggregate welfare should be written as $W = \int_P U(\theta, x^*(\theta))\, d\mu(\theta)$ for a probability measure $\mu$ supported on $P$. The use of $\Haus^{\dH}$ in \eqref{eq:hausdorff-welfare} is justified when $\mu$ is absolutely continuous with respect to $\Haus^{\dH}\!\restriction_P$---a condition that holds, for instance, when $P$ is self-similar under OSC and $\mu$ is the natural invariant measure (with weights $p_k = r_k^{\dH}$). The key economic point is that $\mu$ is \emph{singular} with respect to Lebesgue measure $\lambda^k$ whenever $\dH < k$, so Lebesgue-based welfare integrals assign zero weight to the actual preference support.
		
		\item \textbf{$P$ as the graph of utility.} A preference function $u: [0,1] \to \R$ of Weierstrass type,
		\begin{equation}\label{eq:weierstrass}
			W(x) = \sum_{n=0}^{\infty} a^n \cos(b^n \pi x), \quad 0 < a < 1, \quad ab > 1,
		\end{equation}
		has graph $\Gamma_W \subset \R^2$ with $\dimH(\Gamma_W) = D \in (1,2)$, is continuous but nowhere differentiable, and has \emph{infinite} total variation.
		
		\item \textbf{$P$ as indifference sets.} Beardon and Rowat (2013) proved that efficient sets (indifference curves, Pareto frontiers) in $\R^p$ satisfy $\dimH \leq p-1$, with the bound achievable at \emph{fractional} values by non-smooth sets. Standard smooth indifference manifolds have $\dimH = \dim_{\mathrm{top}} = p-1$ and are therefore ``borderline'' (not fractal in the sense of Definition 2.1). The fractal cases of interest arise when the efficient set is sufficiently non-smooth that $\dim_{\mathrm{top}}(P) < p-1$ while Beardon--Rowat allows $\dimH(P)$ to take fractional values in $(\dim_{\mathrm{top}}(P),\, p-1]$, satisfying $\dimH > \dim_{\mathrm{top}}$. Crucially, the Hausdorff dimension of an indifference set is invariant under monotone transformation, resolving the ordinality objection that graph dimension is cardinal.
	\end{enumerate}
	
	\textbf{Which interpretation where.} The remainder of the paper draws on different interpretations at different points: \Cref{sec:pillar1}'s welfare integral uses (a) (fractal type space); the Coastline Paradox of \Cref{sec:pillar2} and the Brownian tracking model use (b) (graph of a 1D preference function); the welfare economics discussion of \Cref{sec:welfare} uses (c) (fractal boundaries of upper contour sets); and the aggregation analysis of \Cref{sec:aggregation} uses (a)/(c) (fractal acceptable sets). We flag transitions between interpretations as they arise.
	
	\subsection{The Dimension Mismatch Theorem}
	
	The central result of this section is a systematic bias in welfare computation when the assumed dimension of the type space is incorrect.
	
	\begin{theorem}[Dimension Mismatch]\label{thm:dimension-mismatch}
		Let $P \subset \R^k$ be a fractal preference space with $\dimH(P) = \dH \in (0,k)$, and let $s \geq 0$.
		\begin{enumerate}[label=(\roman*)]
			\item If $s > \dH$: $\Haus^s(P) = 0$. In particular, $\lambda^k(P) = \Haus^k(P) = 0$ when $\dH < k$.
			\item If $s < \dH$: $\Haus^s(P) = +\infty$. In particular, $\Haus^1(P) = +\infty$ when $\dH > 1$.
			\item If $s = \dH$: $0 < \Haus^{\dH}(P) < +\infty$ when $P$ is self-similar and satisfies the open set condition (OSC).
		\end{enumerate}
	\end{theorem}
	
	\begin{proof}
		Parts (i) and (ii) are direct consequences of the definition of Hausdorff measure and the characterization of Hausdorff dimension as $\dH = \inf\{s \geq 0 : \Haus^s(P) = 0\} = \sup\{s \geq 0 : \Haus^s(P) = +\infty\}$; see Falconer (2003, Theorem 2.3). Part (iii) is Hutchinson's (1981) theorem for self-similar sets under OSC. Without OSC, $\Haus^{\dH}(P)$ may be zero or infinite even at the critical dimension.
	\end{proof}
	
	\begin{remark}[Economic Interpretation]
		Standard econometrics, treating $\varepsilon$ as draws from a Lebesgue-continuous distribution, implicitly computes welfare by integrating against $\lambda^k$ (or a density with respect to $\lambda^k$). If the true type support has $\dH < k$, then $\lambda^k(P) = 0$: any welfare integral weighted by Lebesgue measure assigns zero mass to the support of heterogeneity. A singular probability measure $\mu$ on $P$ is still well-defined, but Lebesgue-based welfare weights $d\mu/d\lambda^k$ do not exist---the econometrician's welfare computation is biased not because types are ``invisible,'' but because the wrong base measure is used. Conversely, measuring with $\Haus^1$ when $\dH > 1$ gives $\Haus^1(P) = +\infty$: one overestimates heterogeneity by using a ruler of insufficient dimension. Only the correct dimension $\Haus^{\dH}$ yields a finite, economically meaningful welfare integral \eqref{eq:hausdorff-welfare}.
	\end{remark}
	
	\subsection{Calculus on Fractal Domains}
	
	Optimization on fractal preference manifolds requires a notion of differentiation. The $F^\alpha$-calculus of Parvate and Gangal (2009) defines derivatives and integrals on fractal subsets of $\R$ using staircase functions $S_F^\alpha$, enabling a fundamental theorem of calculus on fractals. This one-dimensional calculus provides a conceptual template for fractal marginal rates of substitution: if each good's attribute varies along a fractal subset $F_j \subset \R$, one can envision
	\begin{equation}\label{eq:fractal-mrs}
		\mathrm{MRS}^\alpha = \frac{D_{F_1}^\alpha U}{D_{F_2}^\alpha U},
	\end{equation}
	replacing Debreu's (1972) smooth-preferences framework. Extending this rigorously to multi-good settings (where $F \subset \R^k$) requires a higher-dimensional fractal calculus that is not yet fully developed; we flag this as an open direction rather than a ready-made tool. The natural economic bridge is Galichon's (2016) optimal transport methods, which already employ measure-theoretic machinery for matching markets and discrete choice. Extending from Lebesgue-continuous type distributions to $\Haus^{\dH}$-continuous distributions on fractal supports would be a clean generalization.
	
	\begin{theorem}[Graph Dimension of Weierstrass-Type Preference Functions]\label{thm:graph-dim}
		For Weierstrass-type preference functions \eqref{eq:weierstrass} with integer $b \geq 2$ and $a \in (1/b, 1)$, the Hausdorff dimension of the graph equals the box-counting dimension: $\dimH(\Gamma_W) = \dimB(\Gamma_W) = 2 + \log a / \log b$. Shen (2018) proved this for the classical Weierstrass function $\sum a^n \cos(2\pi b^n x)$ with integer $b \geq 2$, resolving a conjecture of Mandelbrot (1977). Our definition \eqref{eq:weierstrass} uses $\cos(b^n \pi x)$ rather than $\cos(2\pi b^n x)$; the dimension formula is unchanged since the argument involves the scaling ratio $b$ and amplitude ratio $a$, not the specific phase (see Barański, Bárány, and Romanowska 2014 for the general class). Earlier, Hunt (1998) proved the result for random-phase variants. For non-integer $b$ or more general periodic functions, partial results are available (Ren and Shen 2021).
	\end{theorem}
	
	\subsection{BV, Perimeter, and the Coarea Formula: Preference Boundaries as Geometry}
	\label{sec:bv-coarea}
	
	Geometric measure theory provides a precise language for ``roughness.'' Represent a binary choice---whether a given product or action is acceptable in context $x \in \Omega \subset \R^n$---by an acceptance region $E \subseteq \Omega$ with indicator $v = \mathbf{1}_E$. The economically relevant object for marginal personalization is the \emph{boundary} where small context changes flip choices.
	
	\begin{definition}[Bounded Variation and Perimeter; Ambrosio, Fusco, and Pallara 2000]
		A function $f \in L^1(\Omega)$ is in $\BV(\Omega)$ if its distributional derivative $Df$ is a finite Radon measure. The total variation is
		\[
		|Df|(\Omega) := \sup\left\{\int_\Omega f\,\mathrm{div}\,\varphi\dd x :\ \varphi \in C_c^1(\Omega;\R^n),\; \|\varphi\|_\infty \leq 1\right\}.
		\]
		When $f = \mathbf{1}_E$, total variation recovers perimeter: $\TV(\mathbf{1}_E) = |D\mathbf{1}_E|(\Omega) =: P(E;\Omega)$.
	\end{definition}
	
	\begin{theorem}[Coarea Formula; Ambrosio, Fusco, and Pallara 2000; Evans and Gariepy 2015]
		\label{thm:coarea}
		If $f \in \BV(\Omega)$, then
		\[
		|Df|(\Omega) = \int_{-\infty}^{\infty} P(\{f > t\};\Omega)\dd t.
		\]
	\end{theorem}
	
	The coarea formula decomposes total variation into the perimeters of level sets: the ``rougher'' the heterogeneity function $f$, the more boundary mass its level sets carry. Economically, each level set $\{f > t\}$ represents the set of contexts in which utility exceeds threshold $t$; its perimeter measures the discrimination capacity at that threshold. If preference boundaries are fractal enough that their codimension-one Hausdorff measure is infinite---i.e., $\Haus^{n-1}(\partial^* E) = \infty$---then $P(E;\Omega) = \infty$, and the preference indicator is not BV-tame. Coarse averaging erases economically meaningful boundary structure.
	
	\begin{remark}[Value-as-Capacity versus Value-as-Variation]\label{rem:capacity-vs-variation}
		\Cref{thm:dimension-mismatch} reveals two non-equivalent notions of ``economic value'' for a fractal preference support $P$ with $\dimH(P) = \dH$:
		\begin{itemize}[leftmargin=*]
			\item \textbf{Value-as-capacity}: $\Haus^{\dH}(P)$, the Hausdorff measure at intrinsic dimension, is generically finite and positive. It measures how much ``mass'' or ``coverage'' the preference support has in its own geometry. This is the stable, renormalized quantity.
			\item \textbf{Value-as-extractable-variation}: $\Haus^1(P)$ (or $\Haus^{n-1}$ for a boundary in $\R^n$) measures ``how much boundary exists'' when a lower-dimensional interface is used to interact with the set. This quantity can diverge---precisely the coastline divergence.
		\end{itemize}
		The divergence is therefore a \emph{dimension mismatch}: measuring a fractal with the wrong-dimensional ruler. The fractal economy hypothesis centers on the claim that conventional ``general answers'' operate at the wrong dimension, and that generative AI technologies are driving $\delta \to 0$ in a way that makes the mismatch economically actionable.
	\end{remark}
	
	\subsection{Connection to Moderate Utility Models}
	\label{sec:mum-connection}
	
	The fractal preference framework connects naturally to a classical and recently revitalized family of discrete choice models. Halff (1976) introduced the \emph{moderate utility model} (MUM), in which binary choice probabilities take the form
	\begin{equation}\label{eq:mum}
		\rho(i,j) = F\!\left(\frac{u(i) - u(j)}{d(i,j)}\right),
	\end{equation}
	where $u$ is a utility function, $d$ is a distance metric capturing product differentiation, and $F$ is an increasing function with $F(x) = 1 - F(-x)$. He and Natenzon (2024) proved that a binary choice rule admits a MUM representation \emph{if and only if} it satisfies \emph{moderate stochastic transitivity}---a single, directly testable condition intermediate between weak and strong transitivity.
	
	\begin{remark}[Fractal Preferences and the MUM Distance Metric]\label{rem:mum-fractal}
		In our framework, the distance metric $d(i,j)$ inherits the geometric structure of the preference support. When the support $P$ is fractal, nearby products may share many ``preference boundary crossings'' (high perimeter in their vicinity), making them more substitutable---and driving $d(i,j)$ small. Products that lie across a fractal indifference boundary have high differentiation ($d(i,j)$ large) precisely because the boundary is irregular and difficult to navigate. Moderate transitivity---weaker than the strong transitivity required by Fechnerian models but stronger than weak transitivity---provides an empirically disciplined foundation for stochastic choice that accommodates the irregularities induced by fractal preference geometry. The MUM thus characterizes the testable behavioral content of ``fractal-structured heterogeneity'' in binary comparisons, without requiring the analyst to directly estimate the Hausdorff dimension.
	\end{remark}
	
	%% ==========================================================================
	\section{Pillar 2: The Coastline Paradox of Utility}
	\label{sec:pillar2}
	%% ==========================================================================
	
	\subsection{Setup and Definitions}
	
	Consider a preference function $f: [0,1] \to \R$ with graph $\Gamma_f$ having box-counting dimension $\dB \geq 1$. Let $\bar{f} = \int_0^1 f(x)\, dx$ denote the population mean.
	
	\begin{definition}[Surplus Decomposition]
		For resolution $\delta > 0$, define the \emph{$\delta$-grid average} $f_\delta$ as the piecewise-constant function averaging $f$ on intervals of length $\delta$. The \emph{general surplus} is
		\begin{equation}\label{eq:general-surplus}
			S_G = \int_0^1 |f_\delta(x) - \bar{f}|\, dx,
		\end{equation}
		measuring value captured beyond the population mean by a recommendation at resolution $\delta$. The \emph{$\delta$-approximation error} is
		\begin{equation}\label{eq:approx-error}
			A(\delta) = \int_0^1 |f(x) - f_\delta(x)|\, dx,
		\end{equation}
		which converges to zero as $\delta \to 0$ for any continuous $f$ (by uniform continuity on $[0,1]$).
	\end{definition}
	
	The economically relevant measure of latent personalization value is not the approximation error $A(\delta)$ but the \emph{variation-based surplus}---the total amount of preference detail resolved at scale $\delta$, weighted by the marginal value of resolving each unit of detail. Define the \emph{total variation at scale $\delta$} as
	\begin{equation}\label{eq:richardson}
		L(\delta) = \sum_{i=0}^{\lfloor 1/\delta \rfloor - 1} |f((i+1)\delta) - f(i\delta)|,
	\end{equation}
	and the \emph{bespoke surplus} as
	\begin{equation}\label{eq:bespoke-surplus}
		S_B(\delta) = v_0(\delta) \cdot L(\delta),
	\end{equation}
	where $v_0(\delta) > 0$ is the marginal monetizable value per unit of preference variation resolved at scale $\delta$. Each segment $|f((i+1)\delta) - f(i\delta)|$ represents a ``preference detail''---a distinguishable taste difference that a provider can exploit at resolution $\delta$. The factor $v_0(\delta)$ converts geometric complexity into economic value; its scaling with $\delta$ is ultimately an empirical question (see \Cref{rem:joint-scaling} below).
	
	\subsection{Main Result}
	
	\begin{theorem}[Coastline Paradox for Economic Surplus]\label{thm:coastline}
		Let $f: [0,1] \to \R$ be continuous with $\dimB(\Gamma_f) = \dB$.
		\begin{enumerate}[label=(\alph*)]
			\item \textbf{Smooth case} ($f \in \mathrm{BV}$, hence $\dB = 1$): $L(\delta) \to V_f < \infty$, and $S_B(\delta) = v_0(\delta) \cdot V_f \to 0$ whenever $v_0(\delta) \to 0$. Personalization has diminishing returns.
			\item \textbf{Fractal case} ($\dB > 1$): $L(\delta) \sim F \cdot \delta^{1-\dB} \to \infty$ as $\delta \to 0$. The total geometric complexity of preferences is unbounded. The bespoke surplus $S_B(\delta) = v_0(\delta) \cdot L(\delta) \to \infty$ provided marginal monetizability $v_0(\delta)$ decays slower than $\delta^{\dB - 1}$ (see \Cref{rem:joint-scaling}).
			\item General surplus $S_G$ remains bounded for all $\delta$.
			\item $S_B(\delta)/S_G \to \infty$ as $\delta \to 0$ when $\dB > 1$ and $v_0(\delta) = \omega(\delta^{\dB-1})$.
		\end{enumerate}
	\end{theorem}
	
	\begin{proof}[Proof Sketch]
		\textbf{Part (a):} When $f$ has bounded variation, $\dB = 1$ (since the graph is rectifiable; see Falconer 2003, \S11.1). Hence $L(\delta) \leq V_f < \infty$ for all $\delta$, and $S_B(\delta) = v_0(\delta) \cdot L(\delta) \leq v_0(\delta) \cdot V_f$. Note: $\dB = 1$ does not in general imply BV (the converse is false), but $\dB > 1$ does imply unbounded variation, so the regime split is clean in the fractal direction.
		
		\textbf{Part (b):} The scaling $L(\delta) \sim F \cdot \delta^{1-\dB}$ is stated as Assumption A1 in \Cref{tab:assumptions}. The heuristic motivation is as follows. By box-counting, $N_{\mathrm{box}}(\delta) \sim \delta^{-\dB}$ boxes of side $\delta$ cover $\Gamma_f$. Relating $L(\delta)$ to $N_{\mathrm{box}}(\delta) \cdot \delta$ requires that the oscillation of $f$ at scale $\delta$ is distributed roughly uniformly across intervals---a property that holds for self-affine and H\"older-regular processes but not for arbitrary continuous functions. For self-affine functions with uniform H\"older exponent $\alpha$, the relationship $\dB(\Gamma_f) = 2 - \alpha$ gives $L(\delta) \sim \delta^{\alpha - 1} = \delta^{1-\dB}$ directly.
		
		The wavelet perspective makes this transparent: let $\{d_{j,k}\}$ be wavelet coefficients of $f$ at scale $j$ and location $k$. For functions with uniform H\"older exponent $\alpha = 2 - \dB$, coefficient decay satisfies $|d_{j,k}| \sim 2^{-j\alpha}$. The sum of absolute coefficients at scales finer than $\delta = 2^{-J_0}$ is
		\[
		\sum_{j > J_0} \sum_k |d_{j,k}| \sim \sum_{j > J_0} 2^{j(1-\alpha)} = \sum_{j > J_0} 2^{j(\dB - 1)},
		\]
		which diverges when $\dB > 1$ (i.e., $\alpha < 1$). For Brownian motion ($\alpha = 1/2$, $\dB = 3/2$) and Weierstrass functions, both the H\"older condition and the scaling $L(\delta) \sim \delta^{1-\dB}$ hold rigorously.
		
		Note that the $L^1$ approximation error $A(\delta) = \int_0^1 |f(x) - f_\delta(x)| dx$ converges to zero for any continuous $f$ by uniform continuity; it is the \emph{variation} $L(\delta)$, not the approximation error, that diverges. The economic content is that the \emph{number of distinguishable preference details} grows without bound, even though the pointwise mismatch at any fixed location vanishes.
		
		\textbf{Part (c):} $S_G \leq \int_0^1 |f_\delta(x)| + |\bar{f}|\, dx \leq 2\|f\|_\infty < \infty$ since $f$ is continuous on a compact domain.
		
		\textbf{Part (d):} Follows from (b) and (c): $S_B(\delta)/S_G \geq v_0(\delta) \cdot F \delta^{1-\dB} / (2\|f\|_\infty)$, which diverges when $v_0(\delta) = \omega(\delta^{\dB - 1})$.
	\end{proof}
	
	\begin{remark}[The Bounded-Variation Boundary]
		The implication $\mathrm{BV} \implies \dB = 1$ is standard: continuous functions of bounded variation have rectifiable graphs with box-counting dimension~1. The converse, however, is \emph{false}: there exist continuous functions with $\dB(\Gamma_f) = 1$ but unbounded variation. The economically operative regime boundary is therefore \emph{variation-based}: bounded variation (BV) marks the regime where standard economics applies, while $\dB > 1$ is a \emph{sufficient condition} for unbounded variation and thus for the coastline divergence of \Cref{thm:coastline}(b). In the Brownian case ($\dB = 3/2$), both conditions are satisfied unambiguously.
	\end{remark}
	
	\begin{remark}[The Joint Scaling Condition]\label{rem:joint-scaling}
		The divergence of bespoke surplus in \Cref{thm:coastline}(b) is not automatic from fractality alone; it hinges on how \emph{marginal value per newly resolved feature} scales with $\delta$. In fractal geometry, a stable intrinsic measure often appears after renormalization: $\Haus^{\dH}(\Gamma)$ can be finite even though $\Haus^1(\Gamma) = \infty$ (cf.\ \Cref{rem:capacity-vs-variation}). Economically, this corresponds to a diminishing-returns schedule where per-segment monetizability $v_0(\delta)$ decays as $\delta \to 0$. The surplus divergence hypothesis is therefore a \emph{joint scaling claim}:
		\begin{enumerate}[label=(\roman*)]
			\item boundary complexity grows as $L(\delta) \sim \delta^{1-\dB}$, and
			\item marginal monetizability $v_0(\delta)$ decays \emph{slower} than $\delta^{\dB - 1}$,
		\end{enumerate}
		so their product $S_B(\delta) = v_0(\delta) \cdot L(\delta) \to \infty$. If instead $v_0(\delta) \propto \delta^{\dB - 1}$, the bespoke surplus converges---the economy self-renormalizes at its intrinsic dimension, and $S_B$ plays the role of $\Haus^{\dH}(\Gamma)$: a finite, scale-consistent measure of preference richness. Whether condition (ii) holds is ultimately an empirical question; the framework clarifies the precise scaling threshold that separates finite from infinite surplus capacity.
	\end{remark}
	
	\subsection{Multifractal Extension}
	
	For \emph{multifractal} preferences---where the local Hölder exponent $\alpha(x)$ varies across the attribute space---the surplus decomposition is richer. The multifractal spectrum $f(\alpha)$ characterizes the Hausdorff dimension of the set of points with local exponent $\alpha$:
	\begin{equation}\label{eq:multifractal}
		f(\alpha) = \dimH\{x \in [0,1] : \alpha(x) = \alpha\}.
	\end{equation}
	Points with lower $\alpha$ (rougher preferences) contribute disproportionately to bespoke surplus. This yields a practical allocation principle: \emph{resources for personalization should be allocated to the most fractal dimensions of preference first}---e.g., music taste ($\dB$ high) before coffee temperature ($\dB$ low).
	
	\subsection{Empirical Evidence and Practical Limits}
	
	The financial coastline paradox provides empirical motivation. Abdelmessih (2025) documents that daily-based estimates of annualized volatility (18.23\%) exceed weighted averages of within-month volatilities (15.42\%), with the gap attributable to the between-month variance component via the law of total variance. This variance decomposition across regimes is an instance of the broader phenomenon that absolute (total) variation of price paths diverges with sampling frequency, even though realized \emph{quadratic} variation converges (absent microstructure noise) to the integrated variance---exactly the $L^1$/$L^2$ distinction formalized in \Cref{sec:hotelling-loss} and \Cref{prop:tracking}.
	
	Practical limits ensure $S_B(\delta_{\min})$ remains finite for any given technology: privacy constraints impose $\delta_{\min} > 0$; preferences may become smooth below some grain $\delta_0$; and measurement noise may mimic fractal structure. The divergence result characterizes the \emph{frontier}, not the \emph{equilibrium}.
	
	\subsection{Brownian Taste Paths: A Continuous-Time Microfoundation}
	\label{sec:brownian}
	
	The coastline argument (\Cref{thm:coastline}) establishes that \emph{total variation} of preferences diverges when $\dB > 1$. But total variation is not the economically natural loss function. A provider does not pay for every wiggle of taste; they pay for the \emph{integrated squared mismatch} between what they deliver and what the individual wants. Brownian motion provides the cleanest microfoundation for this distinction, and connects the fractal economy to the high-frequency trading literature where the same mathematics was historically regarded as a ``bug.''
	
	\subsubsection{The Model}
	
	Let an individual's instantaneous ideal point $\theta_t \in \R$ evolve as pure Brownian motion:
	\begin{equation}\label{eq:bm-taste}
		d\theta_t = \sigma\, dB_t, \qquad \sigma > 0,
	\end{equation}
	where $\sigma$ parameterizes the \emph{micro-heterogeneity intensity}---how rapidly the individual's true preferences fluctuate at fine temporal or contextual scales. A provider chooses a delivered attribute $a_t$ (recommendation, interface variant, contract term, robot assistance level) to maximize realized surplus:
	\begin{equation}\label{eq:realized-surplus}
		V(\{a_t\}) = \E\!\left[\int_0^T u_t(a_t, \theta_t)\, dt\right], \qquad u_t(a, \theta) = \bar{u} - (a - \theta)^2.
	\end{equation}
	``Unlocking heterogeneity'' is equivalent to reducing the tracking loss $\E[\int_0^T (a_t - \theta_t)^2\, dt]$.
	
	\subsubsection{Technology as Mesh Size}
	
	Suppose legacy technology permits updates only at times $0 = t_0 < t_1 < \cdots < t_n = T$ with uniform spacing $\Delta = T/n$. The best feasible policy with perfect sensing at update times is $a_t = \theta_{t_k}$ for $t \in [t_k, t_{k+1})$. By the standard Brownian scaling property:
	
	\begin{proposition}[Tracking Loss under Brownian Taste Paths]\label{prop:tracking}
		The expected mismatch loss per update interval is
		\begin{equation}\label{eq:interval-loss}
			\E\!\left[\int_{t_k}^{t_{k+1}} (\theta_t - \theta_{t_k})^2\, dt\right] = \frac{1}{2}\sigma^2 \Delta^2.
		\end{equation}
		Summing over $T/\Delta$ intervals, the total expected tracking loss is
		\begin{equation}\label{eq:total-tracking}
			\E\!\left[\int_0^T (a_t - \theta_t)^2\, dt\right] = \frac{1}{2}\sigma^2 T \Delta.
		\end{equation}
	\end{proposition}
	
	\begin{proof}
		For $t \in [t_k, t_{k+1})$, $\theta_t - \theta_{t_k} = \sigma(B_t - B_{t_k})$. Hence $\E[(\theta_t - \theta_{t_k})^2] = \sigma^2(t - t_k)$. Integrating:
		$\int_{t_k}^{t_{k+1}} \sigma^2(t - t_k)\, dt = \sigma^2 \cdot \Delta^2/2$. There are $T/\Delta$ such intervals.
	\end{proof}
	
	The key comparative static is immediate:
	\begin{equation}\label{eq:deadweight}
		\underbrace{\frac{1}{2}\sigma^2 T \Delta}_{\text{deadweight from coarse personalization}} \;\xrightarrow{\;\Delta \to 0\;}\; 0.
	\end{equation}
	As AI/robotics pushes $\Delta \downarrow 0$, wasted surplus vanishes \emph{linearly} in $\Delta$: attainable value $V = \bar{u}T - \frac{1}{2}\sigma^2 T\Delta$ approaches the ceiling $\bar{u}T$ at rate $O(\Delta)$, with no finite resolution at which the marginal gain from further refinement is zero.
	
	\subsubsection{Hotelling Loss and Oracle Surplus}\label{sec:hotelling-loss}
	
	The quadratic mismatch loss in \eqref{eq:realized-surplus} is a natural choice, but not the only one. In spatial competition models since Hotelling (1929), the standard disutility from mismatch is \emph{linear} in distance:
	\begin{equation}\label{eq:hotelling-loss}
		u_t^{L^1}(a, \theta) = \bar{u} - c|a - \theta|, \qquad c > 0.
	\end{equation}
	Under this loss, the oracle provider who perfectly tracks $\theta_t$ at mesh $\Delta$ earns \emph{extractable adjustment rent} from each interval equal to the adjustment magnitude $c|\theta_{t_{k+1}} - \theta_{t_k}|$. This is not the flow-utility welfare (which would require computing $\E\int |a_t - \theta_t|\, dt$ properly), but rather the value of \emph{menu-repricing opportunities}---a measure of the competitive landscape's complexity. Summing over all intervals yields the \emph{oracle adjustment rent}:
	\begin{equation}\label{eq:oracle-surplus}
		\Pi^{\mathrm{oracle}}(\Delta) = c \sum_{k=0}^{n-1} |\theta_{t_{k+1}} - \theta_{t_k}| = c \cdot L(\Delta),
	\end{equation}
	which is exactly the total variation of the taste path at scale $\Delta$. For Brownian motion, $E[L(\Delta)] = \sigma\sqrt{2T/(\pi\Delta)} \to \infty$ as $\Delta \to 0$. This is the precise analog of oracle trading profit in high-frequency finance: a trader who knows the next price increment buys before every uptick and sells before every downtick, earning $\sum |dP_t| = L(\Delta)$. The oracle surplus diverges because each preference wiggle is a separately exploitable opportunity with payoff linear in its magnitude.
	
	The key distinction between L1 and L2 loss is therefore:
	\begin{itemize}[leftmargin=*]
		\item \textbf{$L^1$ (Hotelling) loss:} oracle surplus $= c \cdot L(\Delta) \to \infty$. Each preference shift $|\Delta\theta_k|$ generates surplus proportional to its magnitude, so total value is total variation. Analogous to oracle trading profit.
		\item \textbf{$L^2$ (quadratic) loss:} tracking loss $= \frac{1}{2}\sigma^2 T\Delta \to 0$. Each mismatch generates loss proportional to its square, so total value is quadratic variation ($\sigma^2 T$, finite). Analogous to hedging error.
	\end{itemize}
	Which loss function governs the economy is ultimately an empirical and institutional question. What is common to both is the core fractal economy message: \emph{there is no finite resolution at which the marginal gain from further refinement vanishes}.
	
	\subsubsection{What Brownian Motion Buys Mathematically}
	
	Brownian motion has \emph{infinite total variation} but \emph{finite quadratic variation}. To make this precise:
	
	\begin{definition}[Quadratic Variation; M\"orters and Peres 2010]
		For a continuous semimartingale $X_t$, the quadratic variation on $[0,T]$ is
		\[
		[X]_T := \lim_{\|\pi\| \to 0} \sum_k (X_{t_{k+1}} - X_{t_k})^2,
		\]
		where the limit is in probability over partitions $\pi$ with mesh $\|\pi\| = \max_k(t_{k+1} - t_k)$. For $\theta_t = \sigma B_t$, we have $[\theta]_T = \sigma^2 T$ almost surely.
	\end{definition}
	
	The \emph{realized variance} estimator $RV(\Delta) := \sum_{k=0}^{n-1} (\theta_{t_{k+1}} - \theta_{t_k})^2$ converges to $[\theta]_T$ as $\Delta \downarrow 0$, providing a nonparametric, scale-consistent measure of micro-heterogeneity intensity directly from high-frequency data.
	
	This infinite-variation/finite-energy separation is precisely what the fractal economy requires:
	
	\begin{itemize}[leftmargin=*]
		\item \textbf{Infinite total variation} means there is no privileged scale at which ``preferences stop moving.'' Any finite-resolution technology leaves systematic surplus unexploited; finer measurement and actuation \emph{strictly} increases attainable welfare. This is the continuous-time analog of the coastline divergence in \Cref{thm:coastline}.
		
		\item \textbf{Finite quadratic variation} means that under $L^2$ loss, the economically meaningful object---integrated squared mismatch---scales with $\Delta$, not with total variation. The maximum attainable surplus is bounded above by $\bar{u}T$ (perfect matching), so the goldmine is not infinite total dollars but a large reservoir of \emph{currently unharvested} surplus equal to $\frac{1}{2}\sigma^2 T\Delta_{\mathrm{current}}$. The analogy to high-frequency trading is exact: real HFT firms do not earn infinite profit either---transaction costs impose an optimal $\Delta^* > 0$---but a firm operating at $\Delta = 1$ millisecond captures far more surplus than a monthly rebalancer. Similarly, AI-driven personalization at resolution $\Delta = 1$ second captures strictly more surplus than monthly batch recommendations. The parameter $\sigma^2$, estimable via realized variance, tells us \emph{how much} surplus is at stake.
	\end{itemize}
	
	\begin{remark}[The BM Graph as a Minimal Fractal Example]\label{rem:bm-graph-dim}
		A classical theorem of Taylor (1953; see M\"orters and Peres 2010, Theorem~4.28) states that the Hausdorff dimension of the graph $\{(t, B_t) : t \in [0,1]\}$ of one-dimensional Brownian motion is $3/2$ almost surely. This provides the simplest concrete ``preference coastline'': $\dH = 3/2 > 1$, confirming that any attempt to treat a Brownian preference path as a smooth (rectifiable, 1-dimensional) curve is structurally incorrect.
	\end{remark}
	
	\subsubsection{Occupation Measures and Instance-Space Welfare}
	
	To connect ``local instances'' to measure theory, define the \emph{occupation measure} of the taste path:
	\begin{equation}\label{eq:occupation}
		\mu_T(A) := \int_0^T \mathbf{1}\{\theta_t \in A\}\dd t, \qquad A \subseteq \R\ \text{Borel}.
	\end{equation}
	For Brownian motion, there exists a (random) \emph{local time} density $L_T^x$ such that
	\begin{equation}\label{eq:local-time}
		\int_0^T g(\theta_t)\dd t = \int_{\R} g(x)\, L_T^x\dd x
	\end{equation}
	for suitable $g$. This yields two equivalent welfare representations:
	\begin{itemize}[leftmargin=*]
		\item \textbf{Time-domain welfare} (what the individual experiences): $U(a) = \E\!\int_0^T u(a_t, \theta_t)\dd t$.
		\item \textbf{Instance-domain welfare} (what a product targets): $U(a) = \E\!\int_{\R} u(a(x), x)\, L_T^x\dd x$.
	\end{itemize}
	The instance-domain representation reframes ``local instances'' as the measure-theoretic pushforward of lived time through a high-frequency latent state---exactly the object that product designers optimize over when personalizing at fine resolution.
	
	\begin{remark}[Reconciling Total Variation and Quadratic Variation]\label{rem:reconcile-L1-L2}
		The coastline divergence (\Cref{thm:coastline}), the Hotelling oracle surplus (\Cref{sec:hotelling-loss}), and the Brownian tracking loss (\Cref{prop:tracking}) are three views of the same underlying object---the Brownian preference path---through different economic lenses:
		\begin{itemize}[leftmargin=*]
			\item \textbf{Geometric capacity} (total variation, $L(\Delta) \to \infty$): the number of distinguishable preference details at scale $\Delta$ grows without bound. This measures the complexity of the competitive landscape---how many product niches, menu adjustments, or attention-targeting opportunities exist at each resolution. Under $L^1$ (Hotelling) mismatch loss, each preference wiggle is a separately monetizable opportunity, and oracle surplus equals $c \cdot L(\Delta) \to \infty$ (\Cref{sec:hotelling-loss}).
			\item \textbf{Welfare ceiling} (quadratic variation, $[\theta]_T = \sigma^2 T < \infty$): the total welfare gain from perfect personalization is bounded by $\bar{u}T$, and the unexploited surplus at resolution $\Delta$ is $\frac{1}{2}\sigma^2 T\Delta$---finite, but strictly positive for any $\Delta > 0$. Under $L^2$ (quadratic) mismatch loss, the relevant object is quadratic variation, not total variation.
		\end{itemize}
		The two formulations are not contradictory---they correspond to different loss functions and answer different questions. Under $L^1$, the provider pays per unit of mismatch (as in Hotelling spatial competition or attention-switching costs), and total variation governs value. Under $L^2$, the provider pays per squared unit of mismatch (as in portfolio tracking or recommendation accuracy), and quadratic variation governs value. Both share the core fractal economy conclusion: \emph{no finite resolution exhausts the gains from personalization}. They differ on whether the total gain is infinite ($L^1$, subject to the joint scaling condition of \Cref{rem:joint-scaling}) or finite but underexploited ($L^2$).
	\end{remark}
	
	\begin{remark}[Two Faces of Brownian Heterogeneity: Cross-Sectional and Temporal]\label{rem:lu-saito}
		Brownian motion enters the economics of heterogeneity along two distinct dimensions, and distinguishing them is essential.
		
		\textbf{Cross-sectional (Lu and Saito 2025).} In the pure characteristic model, a consumer has utility $u(x) = v(x) + \varepsilon(x)$ where $\varepsilon(\cdot)$ is a BM on the characteristic space $X$. The consumer selects $\arg\max_{x \in A} u(x)$ from a menu $A$. Lu and Saito prove that this model---unlike mixed logit---satisfies continuity in characteristics and convex substitutability, resolving the pathologies identified by Berry and Pakes (2007). Consumer welfare from a menu at spacing $\delta$ is $W(\delta) = \E[\max_{x \in A} u(x)]$, which converges to the finite limit $\E[\sup_x u(x)]$ as $\delta \to 0$. Crucially, $W(\delta)$ depends on the \emph{maximum} of BM (a distributional property), \emph{not} on the total variation of the BM path. The infinite total variation of $\varepsilon(\cdot)$ over characteristic space is irrelevant to the welfare calculation. BM's role here is purely structural: its continuity ensures the model is a genuine pure characteristic model, and its roughness ensures it is distinct from mixed logit.
		
		\textbf{Temporal (this paper).} In our tracking model, BM describes how a consumer's ideal point $\theta_t$ \emph{evolves} over time or contexts. A provider must follow this moving target at resolution $\Delta$. The tracking problem is where path properties---quadratic variation under $L^2$ loss (\Cref{prop:tracking}), total variation under $L^1$ loss (\Cref{sec:hotelling-loss})---become economically operative. The distinction is that welfare now depends on the \emph{entire path} of preferences (through the integrated mismatch), not just on the maximum at a single moment.
		
		\textbf{The bridge.} Lu and Saito provide the \emph{cross-sectional justification} for why preferences should be modeled as continuous-but-rough (BM-type). Our temporal tracking analysis shows \emph{what happens} when one tries to serve this BM-type consumer over time. Even in the cross-sectional case, total variation has an industrial-organization interpretation: the number of local maxima of $u(x)$ at scale $\delta$ grows as $\sim \delta^{-\dB}$, each representing a viable product niche where a firm could profitably differentiate. Total variation thus measures the \emph{complexity of the competitive landscape}---how many firms and products can coexist---rather than the welfare of any single consumer. This is consistent with Berry and Pakes's finding that, in pure characteristic models, markups shrink to zero as the product space fills up: the market structure grows richer, but per-consumer welfare is bounded.
		
		The unified claim is that BM heterogeneity, whether cross-sectional or temporal, generates fractal preference geometry with $\dH = 3/2 > 1$. Cross-sectionally, this fractality drives market structure (niche count $\sim \delta^{-3/2}$). Longitudinally, it drives the value of personalization (tracking surplus under $L^1$ or $L^2$). AI technologies drive $\delta \to 0$ on both margins simultaneously.
	\end{remark}
	
	\subsubsection{The HFT Inversion: From Bug to Feature}
	
	In high-frequency finance, the infinite total variation of price paths (modeled as semimartingales) is a well-known \emph{problem}: transaction costs proportional to trading frequency imply that the cost of perfect replication diverges as the rebalancing mesh $\Delta \to 0$ (Leland 1985). Realized volatility estimators exhibit the same coastline paradox---measured vol increases with sampling frequency due to microstructure noise superimposed on the diffusive signal. This was a ``bug'' because it meant continuous-time hedging strategies were unimplementable without friction.
	
	We propose the symmetric reinterpretation for personalization. In the HFT context, infinite path variation is costly because the provider (trader) must \emph{pay} for each adjustment. In the personalization context, the provider must \emph{sense and compute} each adjustment---but AI has collapsed the marginal cost of both sensing (data collection) and computing (inference) toward zero, just as it collapsed the cost of general intelligence. The infinite variation that was a liability in trading becomes an asset in personalization: it means there is always more surplus to harvest at finer resolution, with no finite saturation scale at which further refinement yields zero additional value (though the marginal gains from each unit of refinement do diminish as $\Delta \to 0$).
	
	\begin{proposition}[Provider Profit from Capability Improvement]\label{prop:profit}
		Let the provider capture fraction $\alpha \in (0,1)$ of surplus gains. If AI capability raises the feasible update frequency from $1/\Delta_{\mathrm{old}}$ to $1/\Delta_{\mathrm{new}}$, the incremental profit is
		\begin{equation}\label{eq:profit-wedge}
			\Delta\Pi = \alpha \cdot \frac{1}{2}\sigma^2 T\, (\Delta_{\mathrm{old}} - \Delta_{\mathrm{new}}).
		\end{equation}
		Aggregating over a population of $N$ individuals with heterogeneity intensity $\sigma_i$:
		\begin{equation}\label{eq:aggregate-profit}
			\Delta\Pi_{\mathrm{agg}} = \frac{\alpha}{2}\, T\, (\Delta_{\mathrm{old}} - \Delta_{\mathrm{new}}) \sum_{i=1}^N \sigma_i^2.
		\end{equation}
		Returns to finer personalization are largest in high-$\sigma$ domains: attention, health, education, logistics.
	\end{proposition}
	
	\subsubsection{Extensions: Drift, Mean-Reversion, and Multidimensional Tastes}
	
	The pure Brownian motion assumption is a baseline. Three natural extensions preserve the qualitative structure:
	
	\begin{enumerate}[label=(\roman*)]
		\item \textbf{Ornstein--Uhlenbeck (mean-reverting) tastes}: $d\theta_t = -\kappa(\theta_t - \bar\theta)\, dt + \sigma\, dB_t$. This adds a stable long-run mean $\bar\theta$ but preserves the local BM scaling: at time horizons $\Delta \ll 1/\kappa$, the OU process behaves like BM and the tracking loss formula \eqref{eq:total-tracking} holds approximately. Mean-reversion merely imposes a natural ``macro smoothness'' at scales above $1/\kappa$, consistent with the practical limits discussion.
		
		\item \textbf{Fractional Brownian motion (FBM)}: $d\theta_t = \sigma\, dB_t^H$ with Hurst parameter $H \in (0,1)$. For $H < 1/2$ (anti-persistent tastes), micro-heterogeneity is \emph{rougher} than BM; for $H > 1/2$ (persistent), smoother. The tracking loss scales as $\Delta^{2H}$ instead of $\Delta$, so the returns to refinement are even steeper when $H < 1/2$---precisely the regime where the Hurst exponent literature finds many financial series.
		
		\item \textbf{Multidimensional taste vectors}: $\theta_t \in \R^d$ with $d\theta_t = \Sigma\, dB_t$ for $\Sigma \in \R^{d \times d}$. The tracking loss becomes $\frac{1}{2}\mathrm{tr}(\Sigma\Sigma')T\Delta$, and the ``goldmine'' scales with the trace of the diffusion matrix---i.e., the sum of micro-heterogeneity intensities across all preference dimensions.
	\end{enumerate}
	
	%% ==========================================================================
	\section{Pillar 3: The Reciprocal Knowledge Metabolism}
	\label{sec:pillar3}
	%% ==========================================================================
	
	\subsection{Model Setup}
	
	Consider $N$ agents, each with a local dataset $D_i$ drawn from a distribution specific to their ``Local Instance.'' Each agent $i$ chooses effort $e_i \geq 0$ in local optimization (solving their personalization problem). Concretely, $e_i$ parameterizes the number of local SGD steps performed on the current global model $\theta_G$, producing an accumulated model update $g_i(e_i) = \theta_G - \theta_i^{(e_i)}$, where $\theta_i^{(e_i)}$ is the local parameter after $e_i$ gradient steps. This update---not the final gradient at the local optimum, which would be near zero---is shared (via differential privacy) to a global mesh. More local computation increases the informational content of $g_i$ even though the terminal gradient norm shrinks.
	
	Agent $i$'s total utility is:
	\begin{equation}\label{eq:agent-utility}
		U_i = v_i(e_i) - c_i(e_i) + \beta_i \cdot Q\!\left(\sum_{j=1}^N g_j(e_j)\right),
	\end{equation}
	where $v_i(\cdot)$ is private value from local model quality (concave), $c_i(\cdot)$ is computational cost (convex), and $Q(\cdot)$ is the quality of the global model (concave in aggregate gradients). The parameter $\beta_i > 0$ measures agent $i$'s benefit from the global model.
	
	\subsection{Nash Equilibrium and Social Optimum}
	
	The Nash equilibrium first-order condition is:
	\begin{equation}\label{eq:nash-foc}
		v_i'(e_i^*) + \beta_i \cdot Q' \cdot g_i' = c_i'(e_i^*).
	\end{equation}
	The socially optimal Samuelson condition replaces $\beta_i$ with $\sum_j \beta_j$:
	\begin{equation}\label{eq:samuelson}
		v_i'(e_i^{**}) + \left(\sum_{j=1}^N \beta_j\right) \cdot Q' \cdot g_i' = c_i'(e_i^{**}).
	\end{equation}
	The efficiency gap per agent is:
	\begin{equation}\label{eq:gap}
		\Delta_i = \left(\sum_{j \neq i} \beta_j\right) \cdot Q' \cdot g_i'.
	\end{equation}
	
	\subsection{The Respiration Equilibrium}
	
	\begin{proposition}[Respiration Equilibrium]\label{prop:respiration}
		When private benefit dominates the public-good externality,
		\[
		\frac{v_i'(e_i^*)}{\beta_i \cdot Q' \cdot g_i'} \gg 1 \quad \text{for all } i,
		\]
		the Nash effort $e_i^*$ approximates the social optimum $e_i^{**}$. The efficiency ratio
		\[
		\eta = \frac{\sum_i U_i(e^*)}{\sum_i U_i(e^{**})} \to 1
		\]
		as the private-to-public benefit ratio grows.
	\end{proposition}
	
	\begin{proof}
		From \eqref{eq:nash-foc} and \eqref{eq:samuelson}, the wedge is $\Delta_i / c_i'(e_i^*)$. When $v_i' \gg \beta_i Q' g_i'$, the term $c_i'(e_i^*) \approx v_i'(e_i^*)$, and $\Delta_i / c_i'(e_i^*) \approx [\sum_{j \neq i} \beta_j / v_i'(e_i^*)] \cdot Q' \cdot g_i' \to 0$.
	\end{proof}
	
	This result \emph{inverts} standard public-goods intuition: stronger private motivation yields \emph{better} public-good provision, because the public contribution is a technological byproduct carried by the private tide. The structure is closest to the ``joint production'' model of Cornes and Sandler (1984), where private and public goods are produced as co-outputs of the same activity---except here the co-production is not behavioral but \emph{technological}: an agent cannot improve their local model without computing $g_i$, and sharing $g_i$ (via differentially private stochastic gradient descent, DP-SGD; Abadi et al.\ 2016) has near-zero marginal cost once computed. Differential privacy ensures that individual data points cannot be recovered from shared gradients, providing the trust infrastructure that makes ``breathing out'' safe. This is structurally distinct from Andreoni's (1990) warm-glow model, which relies on psychological satisfaction from giving; it is also distinct from standard Lindahl mechanisms, which require willingness-to-pay elicitation for non-rival goods.
	
	\subsection{Residual Free-Riding and Mechanism Design}
	
	Two margins of free-riding persist: \emph{lazy computation} ($e_i = 0$, free-riding on $\theta_G$) and \emph{gradient corruption} (Byzantine behavior). Cong et al.\ (2020) developed FVCG/PVCG mechanisms achieving truthfulness, Pareto efficiency, individual rationality, and weak budget balance for federated learning---the first mechanism with all four properties simultaneously. Ostrom's (1990) eight design principles for commons governance (clearly defined boundaries, proportional benefits, graduated sanctions, collective-choice arrangements) provide the institutional scaffold for the Knowledge Atmosphere.
	
	%% ==========================================================================
	\section{Pillar 4: Fractal Identification---The New Econometrics}
	\label{sec:pillar4}
	%% ==========================================================================
	
	\subsection{From $\beta$ to the IFS}
	
	Standard econometrics identifies a static parameter vector $\beta \in \R^p$. We propose instead to identify the \emph{Iterated Function System} (IFS)---the recursive rule generating an individual's fractal preference.
	
	\begin{definition}[IFS and Attractor]
		An IFS consists of $K$ contraction mappings $\{w_k : \R^n \to \R^n\}_{k=1}^K$, typically affine: $w_k(x) = A_k x + b_k$. By Hutchinson's (1981) theorem, there exists a unique compact set $A$ (the \emph{attractor}) satisfying
		\begin{equation}\label{eq:ifs-attractor}
			A = \bigcup_{k=1}^K w_k(A),
		\end{equation}
		and a unique invariant probability measure $\mu$ with $\mu = \sum_k p_k \cdot \mu \circ w_k^{-1}$.
	\end{definition}
	
	When the $w_k$ are \emph{similitudes} (uniform contractions with $w_k(x) = r_k O_k x + b_k$, $O_k$ orthogonal) satisfying the open set condition, the Hausdorff dimension of $A$ is determined by Moran's equation:
	\begin{equation}\label{eq:moran}
		\sum_{k=1}^K r_k^{\dH} = 1,
	\end{equation}
	where $r_k$ is the contraction ratio of $w_k$. For general \emph{affine} contractions (where $A_k$ may have unequal singular values), the relevant notion is the \emph{affinity dimension}, defined via the singular value function, and Moran's formula with $r_k = \|A_k\|$ provides only an upper bound on $\dimH(A)$. Examples such as Barnsley's fern are self-affine, not self-similar, and their exact Hausdorff dimension requires the more refined theory (Falconer 2003, Ch.~9).
	
	\begin{remark}[Parsimony]
		$K = 3$ affine maps in $\R^2$ require $\sim 21$ parameters but generate a continuum of dimension $\dH \approx 1.585$ (the Sierpinski triangle). This is dramatically more compact than kernel density estimation, basis expansions, or Dirichlet process mixtures: a \emph{finite recursive rule} generating \emph{infinite complexity}.
	\end{remark}
	
	\subsection{Economic Precedent: Fractal Attractors in Optimal Growth}
	
	This pillar builds on an established economic result. Montrucchio and Privileggi (1999) proved that optimal dynamics in a one-sector stochastic Ramsey model with log utility and Cobb--Douglas production under binary shocks constitute an IFS, with the steady-state invariant distribution supported on a fractal (Cantor-like) set. Specifically, for Cobb--Douglas parameter $\alpha < 1/2$ with non-overlapping images, the invariant measure is singular on a Cantor set (Mitra, Montrucchio, and Privileggi 2003).
	
	La Torre et al.\ (2018) extended this to two-sector growth models with random pollution externalities, where optimal trajectories converge to fractal attractors---including Barnsley's fern as an attractor of log-linearized optimal dynamics. The connection to Epstein--Zin recursive utility is natural: the self-referential structure $U_t = W(c_t, \mathrm{CE}_t(U_{t+1}))$ generates IFS-type dynamics when the value function satisfies $V = T(V)$ for a contractive operator $T$.
	
	\subsection{Estimation Algorithms}
	
	Four estimation approaches are directly adaptable from fractal geometry to econometric practice:
	
	\begin{enumerate}[label=(\roman*)]
		\item \textbf{Collage Theorem} (Barnsley 1986, Vrscay 1991). Minimize $d_H(S, \cup_k w_k(S))$ over IFS parameters, where $S$ is observed choice data. The Collage Theorem bounds the error:
		\begin{equation}\label{eq:collage}
			d_H(A, A^*) \leq \frac{1}{1-c} \cdot d_H(S, \cup_k w_k(S)),
		\end{equation}
		where $c$ is the contraction factor and $A^*$ is the estimated attractor.
		
		\item \textbf{Moment Matching / GMM.} The invariant measure's moments satisfy
		\begin{equation}\label{eq:ifs-moments}
			\E_\mu[x^m] = \sum_{k=1}^K p_k \cdot \E_\mu[(A_k x + b_k)^m],
		\end{equation}
		yielding recursive moment conditions estimable via the Generalized Method of Moments (Forte and Vrscay 1995).
		
		\item \textbf{Maximum Likelihood / EM.} Treating map assignments as latent variables, the E-step computes posterior probabilities of which contraction generated each observed transition; the M-step updates parameters. This is structurally identical to finite mixture model estimation (Elton and Piccioni 1992).
		
		\item \textbf{IFS Distribution Function Estimation.} Iacus and La Torre (2001, 2005) provide nonparametric estimation of the invariant distribution function with proven asymptotic equivalence to the empirical CDF, implemented in the R package \texttt{ifs}.
	\end{enumerate}
	
	\subsection{Tractable Identification}
	
	The IFS representation converts an infinite-dimensional identification problem (recovering a fractal set or measure) into a finite-dimensional one (recovering $K$ contraction parameters). We formalize this as follows.
	
	\begin{proposition}[Comparative Parsimony]
		Let $P \subset \R^n$ be the attractor of an IFS with $K$ affine contractions. Then:
		\begin{enumerate}[label=(\alph*)]
			\item Under a restricted canonical family with separation conditions, the IFS generator is identified from the attractor $P$ up to relabeling of maps (Barnsley 1988). Without such restrictions, different contraction families can generate the same attractor or invariant measure (\Cref{rem:non-uniqueness}).
			\item The number of free parameters is $K \cdot (n^2 + n + 1)$ (maps + probabilities).
			\item A nonparametric characterization of $\mu$ via a Dirichlet process requires countably infinite parameters; kernel density estimation in $\R^n$ requires bandwidth selection in $n$ dimensions with $O(h^{-n})$ effective parameters for sample size $h$.
		\end{enumerate}
		The IFS representation is thus more \emph{parsimonious} than the distribution it generates: it compresses the description of heterogeneity into finitely many parameters, even if finding those parameters computationally (the inverse fractal problem) can be non-convex and computationally challenging.
	\end{proposition}
	
	\begin{remark}[Non-Uniqueness and Observational Equivalence]\label{rem:non-uniqueness}
		The main econometric obstacle is that the inverse problem is not globally identifiable without restrictions: different contraction families can generate the same invariant set or measure (Hutchinson 1981 discusses ``different sets of similitudes generating the same set''). This is the structural-econometrics analog of \emph{observational equivalence}. ``Identify the IFS'' therefore typically means one of: (a)~identify an equivalence class of generators; (b)~identify a canonical generator within a restricted family (e.g., affine maps satisfying separation conditions); or (c)~identify \emph{invariants}---dimension, multifractal spectrum, scaling exponents---that are stable across representations. Tractability comes from genuine \emph{recursive structure} in preferences, not from arbitrary complexity: fractality increases identifiability only when the recursion is real.
	\end{remark}
	
	\subsection{Stochastic Generators: Bridging IFS and Brownian Identification}
	\label{sec:stochastic-generators}
	
	The Brownian taste-path model of \Cref{sec:brownian} is itself a generator identification problem, providing a natural bridge between deterministic fractal identification (IFS) and stochastic econometrics:
	\begin{itemize}[leftmargin=*]
		\item \textbf{Deterministic fractal preferences}: estimate an IFS whose attractor/invariant measure represents the preference support. The identified object is the contraction system $\{w_k, p_k\}_{k=1}^K$.
		\item \textbf{Random fractal preferences}: estimate a stochastic generator (diffusion, L\'evy process) whose sample paths exhibit multiscale roughness. The identified object is the \emph{generator law} (e.g., the diffusion coefficient $\sigma^2$), not the path itself.
	\end{itemize}
	In the Brownian case, the realized variance estimator $RV(\Delta) = \sum_k (\theta_{t_{k+1}} - \theta_{t_k})^2 \xrightarrow{p} \sigma^2 T$ as $\Delta \to 0$, providing a nonparametric, $\sqrt{n}$-consistent estimator of the micro-heterogeneity intensity. This connects directly to the high-frequency econometrics literature (Barndorff-Nielsen and Shephard 2002; A\"it-Sahalia and Jacod 2014), where quadratic variation is the fundamental identified object. In this sense, ``fractal identification'' does not mean ``recover the infinite coastline''; it means recover the \emph{scaling law}---the exponents and intensities governing how additional resolution changes predictive error and attainable surplus.
	
	%% ==========================================================================
	\section{Welfare Economics with Fractal Preferences}
	\label{sec:welfare}
	%% ==========================================================================
	
	\subsection{Resolution-Indexed Economies}
	\label{sec:resolution-indexed}
	
	To reconcile fractal preferences with general equilibrium theory, define a family of economies $\{\mathcal{E}_\delta\}_{\delta > 0}$ indexed by the resolution of personalization. In $\mathcal{E}_\delta$, the commodity/contract space is a finite partition of contexts and products at granularity $\delta$. As $\delta \downarrow 0$, the commodity space becomes richer (approaching a continuum or worse). At any fixed $\delta > 0$, standard welfare logic can apply: preferences over finitely many commodities are well-defined, budgets are finite, and the usual GE assumptions (convexity, local nonsatiation, completeness) can be checked. The novelty is that the \emph{limit} $\delta \to 0$ need not preserve these assumptions.
	
	\subsection{Reconciliation with the Fundamental Welfare Theorems}
	
	The reconciliation with the Fundamental Welfare Theorems is asymmetric.
	
	\begin{proposition}[First Welfare Theorem under Fractal Preferences]
		The First Welfare Theorem survives under fractal preferences at each fixed resolution $\delta > 0$, provided preferences are locally non-satiated. We assume local non-satiation holds independently of the fractal structure of the type support: at any fixed $\delta$, the commodity space is finite-dimensional and LNS is a property of the preference relation (specifically, of indifference sets having empty interior in the commodity space), not of the geometry of the type support $P$. Since $\dimH(P) < k$ implies $P$ has Lebesgue measure zero and empty interior in $\R^k$, fractal type supports do not generate thick indifference sets and are thus compatible with LNS. As $\delta \to 0$, the FWT clarifies what must be fixed for efficiency: externalities (knowledge spillovers via the Knowledge Atmosphere), market power in bespoke contracting, and missing markets.
	\end{proposition}
	
	\begin{proposition}[Failure of the Second Welfare Theorem]
		The Second Welfare Theorem fails in its standard form under fractal preferences. The key geometric object is the \emph{upper contour set} $U_\theta = \{x : u(\theta, x) \geq \bar{u}\}$, whose convexity is required for the supporting-hyperplane proof. The boundary of any convex body in $\R^n$ is an $(n-1)$-dimensional Lipschitz manifold with $\dimH(\partial U_\theta) = n-1$. When the boundary $\partial U_\theta$ has $\dimH(\partial U_\theta) \in (n-1, n)$---as arises from fractal indifference surfaces---$U_\theta$ cannot be convex. (Note: a full-dimensional set $U_\theta \subset \R^n$ always has $\dimH(U_\theta) = n$ regardless of convexity; it is the \emph{boundary} dimension that is diagnostic.) As $\delta \to 0$, three failure modes compound: (i)~fractal boundaries produce non-convex upper contour sets, directly blocking the separating hyperplane argument; (ii)~knowledge spillovers create positive externalities absent corrective mechanisms; (iii)~the number of state-contingent contracts required for full completeness explodes.
	\end{proposition}
	
	An \emph{approximate} version may hold. Aliprantis and Burkinshaw (1988) proved approximate welfare theorems without proper preferences, suggesting:
	
	\begin{conjecture}[$\varepsilon$-Second Welfare Theorem]
		For any $\varepsilon > 0$, there exist prices $p$ and transfers $T$ such that the resulting competitive allocation is within $\varepsilon$ (in an appropriate metric on allocations) of any target Pareto optimum, even when preference sets are fractal.
	\end{conjecture}
	
	The fractal lens thus reframes ``market failure'' as \emph{multiscale}: the question is not only whether equilibrium is efficient, but at what resolution $\delta$ the institutional environment supports something like price decentralization without exploding externalities and power asymmetries.
	
	%% ==========================================================================
	\section{The Aggregation Problem}
	\label{sec:aggregation}
	%% ==========================================================================
	
	The mathematical results on Hausdorff dimension under set operations yield a sharp formalization. For $N$ agents, let $P_i \subset X \subset \R^n$ denote agent $i$'s \emph{acceptable set}---the set of alternatives in outcome/policy space $X$ that agent $i$ finds acceptable (interpretation (c) of \Cref{sec:pillar1}). The union $\bigcup_i P_i$ represents the social preference encompassing all individual preferences; the intersection $\bigcap_i P_i$ represents the consensus set of universally acceptable alternatives.
	
	\begin{itemize}[leftmargin=*]
		\item \textbf{Union aggregation} (social preference encompasses all individual preferences):
		\begin{equation}
			\dimH\!\left(\bigcup_{i=1}^N P_i\right) = \max_i \dH^i.
		\end{equation}
		Society is as complex as its most complex member.
		
		\item \textbf{Intersection aggregation} (consensus requires universal agreement). By Mattila's (1984) intersection theorem, for sets in ``generic position'' (formalized via capacity conditions on the relative translations/rotations of the $P_i$):
		\begin{equation}
			\dimH\!\left(\bigcap_{i=1}^N P_i\right) \approx \sum_{i=1}^N \dH^i - (N-1)n,
		\end{equation}
		where the formula gives an upper bound in general, with equality holding for almost every relative position. When $\sum_i \dH^i < (N-1)n$, the intersection is generically empty---no universally acceptable alternative exists. Whether economic preference supports satisfy the genericity conditions is itself an empirical question; the formula provides a benchmark for how consensus shrinks with agent count and preference complexity.
	\end{itemize}
	
	\begin{definition}[Consensus Dimension Deficit]
		The \emph{consensus dimension deficit} is
		\begin{equation}\label{eq:deficit}
			\Delta = \max_i(\dH^i) - \max\!\left(0,\, \sum_i \dH^i - (N-1)n\right).
		\end{equation}
		It measures the fractal richness destroyed by consensus-seeking.
	\end{definition}
	
	The deficit $\Delta$ grows with both $N$ (number of agents) and $n$ (embedding dimension of preference space). In high-dimensional preference spaces---characteristic of modern economies---the destruction is severe. This provides a rigorous formalization of why ``one-size-fits-all'' policy destroys value: the consensus manifold loses most of the fractal richness present in individual preference landscapes.
	
	\subsection{Renormalized Multiscale Social Welfare}
	\label{sec:renormalized-swf}
	
	If each individual's surplus coastline has $BS_i(\delta) \to \infty$, then na\"ive utilitarian aggregation $\sum_i BS_i(\delta)$ diverges as $\delta \to 0$---a mathematical pathology suggesting infinite welfare gains from pure resolution refinement. GMT resolves this as a dimension mismatch (\Cref{rem:capacity-vs-variation}): measuring at the wrong dimension produces spurious infinities. The Brownian model similarly distinguishes infinite variation from bounded utility ceilings ($\bar{u}T$ per individual).
	
	We propose a scale-aware aggregator that remains well-posed:
	\begin{equation}\label{eq:renorm-swf}
		W := \sum_{i=1}^N \left[\int_0^{\delta_0} w(\delta)\dd G_i(\delta) \;-\; \int_0^{\delta_0} w(\delta)\dd C_i(\delta)\right],
	\end{equation}
	where $G_i(\delta)$ is the cumulative gross welfare gain from refining personalization from $\delta_0$ down to $\delta$; $C_i(\delta)$ is the cumulative friction cost (attention, privacy risk, switching costs, governance); and $w(\delta)$ is a scale weight (possibly decreasing) ensuring integrability and reflecting normative priorities. This is the economic analog of using $\Haus^{\dH}$ (finite) rather than $\Haus^1$ (infinite): it measures welfare at the ``correct dimension'' by explicitly incorporating the cost of operating at fine scales.
	
	\begin{remark}[Arrow-Type Obstacles at Fine Resolution]
		If one insists on aggregating ordinal preference information across a rapidly expanding alternative space (as $\delta \to 0$), Arrow's (1951) impossibility theorem warns that no social welfare function can simultaneously satisfy a natural set of fairness and rationality axioms when there are three or more alternatives. In a fractal economy, the number of distinguishable alternatives grows without bound as resolution improves, making Arrow-type tensions \emph{more}, not less, salient. This strengthens the case for multiscale mechanism design and constrained aggregators like \eqref{eq:renorm-swf}, rather than a single smooth social preference ordering.
	\end{remark}
	
	%% ==========================================================================
	\section{Summary Tables}
	\label{sec:tables}
	%% ==========================================================================
	
	\begin{table}[ht]
		\centering
		\caption{Key geometric objects and their economic interpretations.}
		\label{tab:objects}
		\begin{tabular}{>{\raggedright\arraybackslash}p{0.20\linewidth}
				>{\raggedright\arraybackslash}p{0.20\linewidth}
				>{\raggedright\arraybackslash}p{0.18\linewidth}
				>{\raggedright\arraybackslash}p{0.34\linewidth}}
			\toprule
			\textbf{Object} & \textbf{Measure / notion} & \textbf{Dimension} & \textbf{Economic interpretation} \\
			\midrule
			Preference support $P \subset X$ & Hausdorff measure $\Haus^s(P)$ & $\dimH(P) = \dH$ & ``Mass'' of relevant contexts; intrinsic complexity of where value can be created. \\[4pt]
			Boundary $\Gamma$ & Measured length $L(\delta)$ & Effective $\dH > 1$ & ``Coastline'' of preference; discrimination capacity grows as $\delta \downarrow 0$. \\[4pt]
			Binary choice $E \subset \Omega$ & Perimeter $P(E)$ & Codim-1; BV framework & Boundary complexity analyzed via perimeter/BV theory; fractal boundaries push $P(E) \to \infty$, beyond the BV-tame regime. \\[4pt]
			Taste path $\theta_t$ & Quadratic variation $[\theta]_T$ & $\dimH(\mathrm{Graph}) = 3/2$ & Scale-consistent roughness; identifies $\sigma^2$; governs tracking loss scaling. \\[4pt]
			Occupation measure $\mu_T$ & $\mu_T(A) = \int_0^T \mathbf{1}\{\theta_t \in A\}\dd t$ & Local time density & ``Instance distribution'' over tastes; converts time welfare to instance-space integrals. \\
			\bottomrule
		\end{tabular}
	\end{table}
	
	\begin{table}[ht]
		\centering
		\caption{Core assumptions and the results they support.}
		\label{tab:assumptions}
		\begin{tabular}{>{\raggedright\arraybackslash}p{0.08\linewidth}
				>{\raggedright\arraybackslash}p{0.60\linewidth}
				>{\raggedright\arraybackslash}p{0.24\linewidth}}
			\toprule
			\textbf{Label} & \textbf{Content} & \textbf{Used in} \\
			\midrule
			A1 & Boundary scaling: $L(\delta) \geq c\,\delta^{1-\dB}$ with $\dB > 1$. & \Cref{thm:coastline}, \S\ref{sec:pillar2}. \\[3pt]
			A2 & Local monetizability: value density along resolvable boundary bounded below by $v_0 > 0$. & \Cref{thm:coastline}, \Cref{rem:joint-scaling}. \\[3pt]
			A3 & Taste evolves as diffusion: $d\theta_t = \sigma\dd B_t$. & \Cref{prop:tracking}, \S\ref{sec:brownian}. \\[3pt]
			A4 & Quadratic-loss utility: $u = \bar{u} - (a - \theta)^2$. & \Cref{prop:tracking} (tracking loss). \\[3pt]
			A5 & Mechanism updates on mesh $\Delta$; $a_t$ piecewise constant. & \Cref{prop:tracking} (resolution economics). \\[3pt]
			A6 & Differentiability/convexity for participation game. & \Cref{prop:respiration}, \S\ref{sec:pillar3}. \\[3pt]
			A7 & GE welfare assumptions (convexity, nonsatiation) hold at fixed $\delta$. & \S\ref{sec:welfare}, \S\ref{sec:resolution-indexed}. \\
			\bottomrule
		\end{tabular}
	\end{table}
	
	%% ==========================================================================
	\section{Discussion and Research Agenda}
	\label{sec:discussion}
	%% ==========================================================================
	
	\subsection{Immediate Empirical Tests}
	
	The most immediate empirical test is straightforward: estimate the box-counting dimension of revealed preference data in consumer panels. If $\dB$ is significantly and robustly greater than 1, the entire framework activates. If $\dB \approx 1$, standard smooth-preferences economics suffices. Note that even the baseline case of Brownian motion ($H = 0.5$) already yields $\dB = 3/2 > 1$ (\Cref{rem:bm-graph-dim}), so the fractal hypothesis does not require $H \neq 0.5$. The Hurst exponent literature in finance (six decades of evidence for $H \neq 0.5$) is suggestive of additional roughness or long memory beyond standard BM, which would further increase the returns to fine-grained personalization---but the cross-sectional preference version of this test has never been conducted.
	
	Specific approaches include:
	\begin{enumerate}[label=(\roman*)]
		\item Box-counting analysis of individual choice sequences in scanner panel data.
		\item Detrended fluctuation analysis of preference stability across product categories.
		\item IFS fitting to revealed preference data with model selection over $K$.
		\item Comparison of IFS-based prediction versus standard discrete choice models.
		\item Estimation of $\sigma^2$ (micro-heterogeneity intensity) from high-frequency choice data, testing whether tracking loss scales linearly in $\Delta$ as predicted by \Cref{prop:tracking}.
		\item Cross-domain comparison of Hurst exponents to characterize differences in \emph{scaling structure} (roughness) across product categories (e.g., music vs.\ groceries vs.\ health), with $\sigma^2$ estimated separately to identify high-intensity personalization frontiers. Low $H$ (rough, anti-persistent preferences) implies steeper returns to resolution refinement; high $\sigma^2$ implies larger absolute surplus at any given resolution.
	\end{enumerate}
	
	\subsection{Connections to Existing Research Programs}
	
	The framework draws on and extends eight established research streams:
	\begin{enumerate}[label=(\roman*)]
		\item \textbf{Geometric measure theory}: Hausdorff measure, fractal dimension, BV functions, coarea formula (Federer 1969, Falconer 2003, Ambrosio, Fusco, and Pallara 2000, Evans and Gariepy 2015).
		\item \textbf{Fractal finance}: Mandelbrot (1963--1997), Peters (1991), Calvet and Fisher (2008).
		\item \textbf{Market microstructure}: transaction cost scaling under infinite variation (Leland 1985); realized volatility and the coastline paradox at high frequency (Barndorff-Nielsen and Shephard 2002, A\"it-Sahalia and Jacod 2014).
		\item \textbf{Stochastic optimal control}: Montrucchio and Privileggi (1999), La Torre et al.\ (2018).
		\item \textbf{Discrete choice theory}: the pure characteristic demand model and its advantages over mixed logit (Berry and Pakes 2007; Lu and Saito 2025); moderate utility models (Halff 1976, He and Natenzon 2024).
		\item \textbf{Federated learning}: McMahan et al.\ (2016), Cong et al.\ (2020).
		\item \textbf{Complexity economics}: Arthur (2021), Beinhocker (2006), the Santa Fe Institute tradition.
		\item \textbf{Welfare economics and social choice}: Arrow (1951), Debreu (1972); approximate welfare theorems (Aliprantis, Tourky, and Yannelis 1988).
	\end{enumerate}
	
	\subsection{Open Questions}
	
	Several foundational questions remain:
	\begin{enumerate}[label=(\roman*)]
		\item Is cross-sectional preference heterogeneity empirically self-similar?
		\item Can the $\varepsilon$-Second Welfare Theorem be proven formally for fractal preference sets?
		\item What is the optimal mechanism for a social planner who knows the fractal dimension $\dH$ but not the IFS parameters?
		\item How does fractal identification perform relative to deep learning approaches for preference prediction?
		\item What is the empirical Hurst exponent of individual-level preference dynamics in scanner panel data, and does it differ systematically across product categories (high-$\sigma$ domains versus low)?
		\item Can the Leland (1985) hedging-with-transaction-costs framework be formally dualized into an optimal-personalization-with-sensing-costs framework, yielding a ``modified AI capability'' analog of the modified Black--Scholes equation?
	\end{enumerate}
	
	%% ==========================================================================
	%% REFERENCES
	%% ==========================================================================
	\newpage
	\section*{References}
	\addcontentsline{toc}{section}{References}
	
	\begin{description}[style=nextline, leftmargin=0pt, font=\normalfont]
		
		\item[Abadi, M., Chu, A., Goodfellow, I., McMahan, H.B., Mironov, I., Talwar, K., and Zhang, L. (2016).] ``Deep Learning with Differential Privacy.'' \emph{Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security}, 308--318.
		
		\item[Abdelmessih, K. (2025).] ``The Coastline Paradox in Financial Markets.'' Moontower Meta.
		
		\item[A\"it-Sahalia, Y. and Jacod, J. (2014).] \emph{High-Frequency Financial Econometrics}. Princeton University Press.
		
		\item[Aliprantis, C.D. and Burkinshaw, O. (1988).] ``The Fundamental Theorems of Welfare Economics without Proper Preferences.'' \emph{Journal of Mathematical Economics}, 17(1), 41--54.
		
		\item[Ambrosio, L., Fusco, N., and Pallara, D. (2000).] \emph{Functions of Bounded Variation and Free Discontinuity Problems}. Oxford University Press.
		
		\item[Andreoni, J. (1990).] ``Impure Altruism and Donations to Public Goods: A Theory of Warm-Glow Giving.'' \emph{Economic Journal}, 100(401), 464--477.
		
		\item[Arrow, K.J. (1951).] \emph{Social Choice and Individual Values}. Wiley.
		
		\item[Arthur, W.B. (2021).] ``Foundations of Complexity Economics.'' \emph{Nature Reviews Physics}, 3, 136--145.
		
		\item[Barański, K., Bárány, B., and Romanowska, J. (2014).] ``On the Dimension of the Graph of the Classical Weierstrass Function.'' \emph{Advances in Mathematics}, 265, 32--59.
		
		\item[Berry, S. and Pakes, A. (2007).] ``The Pure Characteristics Demand Model.'' \emph{International Economic Review}, 48(4), 1193--1225.
		
		\item[Berry, S., Levinsohn, J., and Pakes, A. (1995).] ``Automobile Prices in Market Equilibrium.'' \emph{Econometrica}, 63(4), 841--890.
		
		\item[Barndorff-Nielsen, O.E. and Shephard, N. (2002).] ``Econometric Analysis of Realized Volatility and Its Use in Estimating Stochastic Volatility Models.'' \emph{Journal of the Royal Statistical Society: Series B}, 64(2), 253--280.
		
		\item[Barnsley, M.F. (1986).] ``Fractal Functions and Interpolation.'' \emph{Constructive Approximation}, 2, 303--329.
		
		\item[Barnsley, M.F. (1988).] \emph{Fractals Everywhere}. Academic Press.
		
		\item[Beardon, A.F. and Rowat, C. (2013).] ``Efficient Sets Are Small.'' \emph{Journal of Mathematical Economics}, 49(5), 367--374.
		
		\item[Beinhocker, E. (2006).] \emph{The Origin of Wealth}. Harvard Business School Press.
		
		\item[Calvet, L.E. and Fisher, A.J. (2008).] \emph{Multifractal Volatility}. Academic Press.
		
		\item[Cong, M., Yu, H., Weng, X., and Yiu, S.M. (2020).] ``A VCG-based Fair Incentive Mechanism for Federated Learning.'' \emph{arXiv:2008.06680}.
		
		\item[Cornes, R. and Sandler, T. (1984).] ``Easy Riders, Joint Production, and Public Goods.'' \emph{Economic Journal}, 94(375), 580--598.
		
		\item[Debreu, G. (1972).] ``Smooth Preferences.'' \emph{Econometrica}, 40(4), 603--615.
		
		\item[Elton, J. and Piccioni, M. (1992).] ``Iterated Function Systems Arising from Recursive Estimation Problems.'' \emph{Probability Theory and Related Fields}, 91, 1--26.
		
		\item[Evans, L.C. and Gariepy, R.F. (2015).] \emph{Measure Theory and Fine Properties of Functions}, rev.\ ed. CRC Press.
		
		\item[Falconer, K. (2003).] \emph{Fractal Geometry: Mathematical Foundations and Applications}, 2nd ed. Wiley.
		
		\item[Federer, H. (1969).] \emph{Geometric Measure Theory}. Springer.
		
		\item[Forte, B. and Vrscay, E.R. (1995).] ``Solving the Inverse Problem for Function/Image Approximation Using Iterated Function Systems.'' \emph{Fractals}, 3(2), 327--346.
		
		\item[Gao, W. (2026).] ``Towards the Distributed Knowledge Atmosphere.'' Unpublished essay.
		
		\item[Galichon, A. (2016).] \emph{Optimal Transport Methods in Economics}. Princeton University Press.
		
		\item[Gneiting, T., Ševčíková, H., and Percival, D.B. (2012).] ``Estimators of Fractal Dimension: Assessing the Roughness of Time Series and Spatial Data.'' \emph{Statistical Science}, 27(2), 247--277.
		
		\item[Halff, H.M. (1976).] ``Choice Theories for Differentially Comparable Alternatives.'' \emph{Journal of Mathematical Psychology}, 14(3), 244--246.
		
		\item[He, J. and Natenzon, P. (2024).] ``Moderate Utility.'' \emph{American Economic Review: Insights}, 6(2), 176--195.
		
		\item[Hunt, B.R. (1998).] ``The Hausdorff Dimension of Graphs of Weierstrass Functions.'' \emph{Proceedings of the American Mathematical Society}, 126(3), 791--800.
		
		\item[Hutchinson, J.E. (1981).] ``Fractals and Self-Similarity.'' \emph{Indiana University Mathematics Journal}, 30(5), 713--747.
		
		\item[Iacus, S.M. and La Torre, D. (2001).] ``A Note on the Estimation of the Distribution Function of a Process by Random Iterated Function Systems.'' \emph{Universit\`a degli Studi di Milano}, Working Paper.
		
		\item[Iacus, S.M. and La Torre, D. (2005).] ``Approximating Distribution Functions by Iterated Function Systems.'' \emph{Journal of Applied Mathematics and Decision Sciences}, 2005(1), 33--46.
		
		\item[La Torre, D., Marsiglio, S., Mendivil, F., and Privileggi, F. (2018).] ``Fractal Attractors in Economic Growth Models with Random Pollution Externalities.'' \emph{Chaos}, 28(5), 055916.
		
		\item[Leland, H.E. (1985).] ``Option Pricing and Replication with Transactions Costs.'' \emph{Journal of Finance}, 40(5), 1283--1301.
		
		\item[Lu, J. and Saito, K. (2025).] ``Mixed Logit Versus Pure Characteristics Models.'' Working paper.
		
		\item[McFadden, D. (1974).] ``Conditional Logit Analysis of Qualitative Choice Behavior.'' In P.~Zarembka (ed.), \emph{Frontiers in Econometrics}, 105--142. Academic Press.
		
		\item[Mandelbrot, B.B. (1963).] ``The Variation of Certain Speculative Prices.'' \emph{Journal of Business}, 36(4), 394--419.
		
		\item[Mandelbrot, B.B. (1967).] ``How Long Is the Coast of Britain? Statistical Self-Similarity and Fractional Dimension.'' \emph{Science}, 156(3775), 636--638.
		
		\item[Mandelbrot, B.B. (1977).] \emph{Fractals: Form, Chance, and Dimension}. W.H.\ Freeman.
		
		\item[Mandelbrot, B.B. (1997).] \emph{Fractals and Scaling in Finance}. Springer.
		
		\item[Mandelbrot, B.B. and Van Ness, J.W. (1968).] ``Fractional Brownian Motions, Fractional Noises and Applications.'' \emph{SIAM Review}, 10(4), 422--437.
		
		\item[Mattila, P. (1984).] ``Hausdorff Dimension and Capacities of Intersections of Sets in $n$-Space.'' \emph{Acta Mathematica}, 152, 77--105.
		
		\item[McMahan, H.B., Moore, E., Ramage, D., Hampson, S., and y Arcas, B.A. (2016).] ``Communication-Efficient Learning of Deep Networks from Decentralized Data.'' \emph{arXiv:1602.05629}.
		
		\item[Mitra, T., Montrucchio, L., and Privileggi, F. (2003).] ``The Nature of the Steady State in Models of Optimal Growth under Uncertainty.'' \emph{Economic Theory}, 23, 39--71.
		
		\item[Montrucchio, L. and Privileggi, F. (1999).] ``Fractal Steady States in Stochastic Optimal Control Models.'' \emph{Annals of Operations Research}, 88, 183--197.
		
		\item[M\"orters, P. and Peres, Y. (2010).] \emph{Brownian Motion}. Cambridge University Press.
		
		\item[Ostrom, E. (1990).] \emph{Governing the Commons}. Cambridge University Press.
		
		\item[Parvate, A. and Gangal, A.D. (2009).] ``Calculus on Fractal Subsets of Real Line.'' \emph{Fractals}, 17(1), 53--81.
		
		\item[Peters, E.E. (1991).] \emph{Chaos and Order in the Capital Markets}. Wiley.
		
		\item[Ren, H. and Shen, W. (2021).] ``A Dichotomy for the Weierstrass-Type Functions.'' \emph{Inventiones Mathematicae}, 226, 1057--1100.
		
		\item[Shen, W. (2018).] ``Hausdorff Dimension of the Graphs of the Classical Weierstrass Functions.'' \emph{Mathematische Zeitschrift}, 289, 223--266.
		
		\item[Taylor, S.J. (1953).] ``The $\alpha$-Dimensional Measure of the Graph and Set of Zeros of a Brownian Path.'' \emph{Proceedings of the Cambridge Philosophical Society}, 49, 31--39.
		
		\item[Vrscay, E.R. (1991).] ``Moment and Collage Methods for the Inverse Problem of Fractal Construction with Iterated Function Systems.'' In \emph{Fractals in the Fundamental and Applied Sciences}, North-Holland.
		
		\item[Varian, H.R. (2003).] ``Economics of Information Technology.'' Mattioli Lecture, \emph{Universit\`a di Torino}.
		
	\end{description}
	
\end{document}
